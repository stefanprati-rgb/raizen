#!/usr/bin/env python3
"""
Script de Varredura Final (Catando Milho) - CPFL
Objetivo: Preencher QUALQUER campo critico que ainda esteja vazio.
Prompt din√¢mico por arquivo.
"""

import os
import sys
import json
import time
import pandas as pd
from pathlib import Path
import google.generativeai as genai
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

# Carregar vari√°veis de ambiente
load_dotenv()

# Configura√ß√µes Turbo
BASE_DIR = Path("C:/Projetos/Raizen/data/processed")
CSV_PATH = Path("C:/Projetos/Raizen/output/datasets_consolidados/CPFL_PAULISTA/CPFL_PAULISTA.csv")
MODEL_NAME = "gemini-2.5-flash-lite"
MAX_WORKERS = 50 

# Campos alvo para verifica√ß√£o
TARGET_FIELDS = [
    "data_adesao",
    "participacao_percentual",
    "num_instalacao",
    "num_cliente",
    "aviso_previo",
    "fidelidade",
    "razao_social",
    "cnpj"
]

csv_lock = Lock()

def setup_gemini():
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        print("‚ùå Erro: GEMINI_API_KEY n√£o encontrada.")
        sys.exit(1)
    genai.configure(api_key=api_key)

def process_single_pdf(args):
    idx, row, pdf_path, missing_fields = args
    if not pdf_path or not os.path.exists(pdf_path): return (idx, None, "PDF n√£o encontrado")

    try:
        sample_file = genai.upload_file(path=str(pdf_path))
        
        # Timeout loop
        start = time.time()
        while sample_file.state.name == "PROCESSING":
            if time.time() - start > 60: return (idx, None, "Timeout")
            time.sleep(1)
            sample_file = genai.get_file(sample_file.name)
            
        if sample_file.state.name == "FAILED": return (idx, None, "Failed")

        # Prompt Din√¢mico
        prompt = f"""
        Analise este contrato de energia (CPFL) com extrema aten√ß√£o.
        Precisamos encontrar os seguintes valores que est√£o faltando: {', '.join(missing_fields)}.
        
        Regras de Extra√ß√£o:
        - data_adesao: Procure em logs de assinatura, cabe√ßalho ou rodap√©. Formato DD/MM/AAAA.
        - num_cliente: C√≥digo do cliente na distribuidora (Geralmente no cabe√ßalho da conta ou contrato).
        - num_instalacao: C√≥digo da Instala√ß√£o/UC.
        - participacao_percentual: Procure por "Rateio", "Cota", "Participa√ß√£o", "Aloca√ß√£o".
        
        Retorne um JSON APENAS com os campos encontrados:
        {{
            "campo_encontrado": "valor"
        }}
        Se n√£o encontrar, n√£o inclua no JSON ou use null.
        """

        model = genai.GenerativeModel(MODEL_NAME)
        response = model.generate_content(
            [sample_file, prompt],
            generation_config={"response_mime_type": "application/json"}
        )
        
        try: genai.delete_file(sample_file.name)
        except: pass
            
        return (idx, json.loads(response.text), None)
    except Exception as e:
        return (idx, None, str(e))

def find_pdf_path(filename, base_dir):
    candidate = base_dir / "16_paginas/CPFL_PAULISTA" / filename
    if candidate.exists(): return candidate
    for subdir in ["05_paginas", "11_paginas", "02_paginas"]:
        candidate = base_dir / subdir / "CPFL_PAULISTA" / filename
        if candidate.exists(): return candidate
    results = list(base_dir.rglob(filename))
    if results: return results[0]
    return None

def main():
    print("="*60)
    print(f"VARREDURA FINAL (CATANDO MILHO) - {MAX_WORKERS} threads")
    print("="*60)
    
    setup_gemini()
    
    df = pd.read_csv(CSV_PATH, sep=";", low_memory=False)
    
    tasks = []
    print("Identificando gaps...", flush=True)
    
    for idx, row in df.iterrows():
        missing = []
        for field in TARGET_FIELDS:
            if field not in df.columns or pd.isna(row[field]) or str(row[field]).strip() == "":
                missing.append(field)
        
        if missing:
            pdf_path = find_pdf_path(row["arquivo_origem"], BASE_DIR)
            tasks.append((idx, row, pdf_path, missing))
            
    print(f"Total na base: {len(df)}")
    print(f"Contratos com gaps: {len(tasks)}")
    
    if len(tasks) == 0:
        print("‚úÖ Tudo 100% preenchido! Nada para catar.")
        return

    completed = 0
    recuperados = 0
    
    print("Iniciando workers...", flush=True)
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = [executor.submit(process_single_pdf, t) for t in tasks]
        
        for future in as_completed(futures):
            idx, result, error = future.result()
            completed += 1
            
            if result:
                changes = []
                with csv_lock:
                    for k, v in result.items():
                        if k in TARGET_FIELDS and v and str(v).lower() != "null":
                             df.at[idx, k] = v
                             changes.append(f"{k}={v}")
                
                if changes:
                    recuperados += 1
                    print(f"[{completed}/{len(tasks)}] üåΩ RECUPERADO: {', '.join(changes)}", flush=True)
                else:
                    print(f"[{completed}/{len(tasks)}] üîπ (N√£o encontrado)", flush=True)
            else:
                print(f"[{completed}/{len(tasks)}] ‚ùå {error or 'Vazio'}", flush=True)

            if completed % 50 == 0:
                with csv_lock:
                    df.to_csv(CSV_PATH, sep=";", index=False)
                    print("üíæ Checkpoint", flush=True)

    df.to_csv(CSV_PATH, sep=";", index=False)
    print(f"\nüèÅ FIM! Registros melhorados: {recuperados}")

if __name__ == "__main__":
    main()
